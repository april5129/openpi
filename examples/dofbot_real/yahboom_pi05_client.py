#!/usr/bin/env python3
"""
Linuså¼æç®€å®ç°: è¿æ¥è¿œç¨‹pi0.5æ¨¡å‹æ§åˆ¶æœ¬åœ°æœºæ¢°è‡‚
é›¶åºŸè¯ï¼Œé›¶ç‰¹æ®Šæƒ…å†µï¼Œé›¶è¿‡åº¦è®¾è®¡
"""

import time
import numpy as np
import cv2
import os
import threading
from datetime import datetime
from Arm_Lib import Arm_Device
from openpi_client import websocket_client_policy


class YahboomPi05Client:
    """æœ€ç®€WebSocketå®¢æˆ·ç«¯ - ä¸€ä¸ªç±»è§£å†³æ‰€æœ‰é—®é¢˜"""
    
    # Dofbotå…³èŠ‚å®šä¹‰å’Œé™åˆ¶ (åŸºäºYahboom Dofbot 6DOFè§„æ ¼)
    JOINT_NAMES = [
        "base_rotation",      # å…³èŠ‚1: åº•åº§æ—‹è½¬ (0-180Â°)
        "shoulder",           # å…³èŠ‚2: è‚©éƒ¨ (0-180Â°) 
        "elbow",             # å…³èŠ‚3: è‚˜éƒ¨ (0-180Â°)
        "wrist_pitch",       # å…³èŠ‚4: è…•éƒ¨ä¿¯ä»° (0-180Â°)
        "wrist_roll",        # å…³èŠ‚5: è…•éƒ¨ç¿»æ»š (0-180Â°)
        "gripper"            # å…³èŠ‚6: å¤¹çˆª (0-180Â°)
    ]
    
    # æ¯ä¸ªå…³èŠ‚çš„å®é™…è§’åº¦èŒƒå›´ [min, max] (åº¦)
    JOINT_LIMITS = [
        [0, 180],    # base_rotation: åº•åº§å¯å…¨èŒƒå›´æ—‹è½¬
        [0, 180],    # shoulder: è‚©éƒ¨å…³èŠ‚èŒƒå›´
        [0, 180],    # elbow: è‚˜éƒ¨å…³èŠ‚èŒƒå›´  
        [0, 180],    # wrist_pitch: è…•éƒ¨ä¿¯ä»°èŒƒå›´
        [0, 180],    # wrist_roll: è…•éƒ¨ç¿»æ»šèŒƒå›´
        [0, 180]     # gripper: å¤¹çˆªå¼€åˆèŒƒå›´
    ]
    
    # å®‰å…¨çš„åˆå§‹ä½ç½® (åº¦) - é¿å…å¥‡å¼‚ç‚¹å’Œç¢°æ’
    SAFE_POSITION = [90, 135, 0, 1, 89, 3]  # æ›´å®‰å…¨çš„å§¿æ€
    
    def __init__(self, server_host="12.148.158.61", server_port=8000):
        self.arm = Arm_Device()
        time.sleep(0.1)
        
        # ç§»åŠ¨åˆ°å®‰å…¨ä½ç½®
        print("ğŸ”§ ç§»åŠ¨æœºæ¢°è‡‚åˆ°å®‰å…¨ä½ç½®...")
        self.arm.Arm_serial_servo_write6(*self.SAFE_POSITION, 1500)  # æ…¢é€Ÿç§»åŠ¨åˆ°å®‰å…¨ä½ç½®
        time.sleep(2.0)  # ç­‰å¾…ç§»åŠ¨å®Œæˆ
        print("âœ… æœºæ¢°è‡‚å·²å°±ä½")
        
        # å½“å‰çŠ¶æ€ - ä½¿ç”¨å®‰å…¨ä½ç½®åˆå§‹åŒ–
        self.joint_angles = list(self.SAFE_POSITION)
        
        # å¹¶è¡Œæ‰§è¡Œç›¸å…³çŠ¶æ€
        self.joint_angles_lock = threading.Lock()  # ä¿æŠ¤å…³èŠ‚çŠ¶æ€çš„é”
        self.next_prediction = None  # å­˜å‚¨ä¸‹ä¸€è½®é¢„æµ‹ç»“æœ
        self.prediction_lock = threading.Lock()  # ä¿æŠ¤é¢„æµ‹ç»“æœçš„é”
        self.is_predicting = False  # æ˜¯å¦æ­£åœ¨è¿›è¡Œé¢„æµ‹
        
        # è®¾ç½®å›¾åƒä¿å­˜ç›®å½•
        self.images_dir = "/home/yahboom/openpi/examples/dofbot_real/images"
        os.makedirs(self.images_dir, exist_ok=True)
        self.step_counter = 0  # ç”¨äºå›¾åƒæ–‡ä»¶å‘½å
        print(f"ğŸ“ å›¾åƒä¿å­˜ç›®å½•: {self.images_dir}")
        
        # è¿æ¥åˆ°è¿œç¨‹pi0.5æœåŠ¡å™¨
        print(f"è¿æ¥åˆ°è¿œç¨‹æœåŠ¡å™¨: {server_host}:{server_port}")
        self.policy = websocket_client_policy.WebsocketClientPolicy(
            host=server_host,
            port=server_port
        )
        print(f"âœ… è¿æ¥æˆåŠŸ! æœåŠ¡å™¨å…ƒæ•°æ®: {self.policy.get_server_metadata()}")
    
    def _save_images(self, original_frame, processed_frame):
        """ä¿å­˜åŸå§‹å›¾åƒå’Œå¤„ç†åçš„å›¾åƒ"""
        try:
            # ç”Ÿæˆæ—¶é—´æˆ³
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # ä¿å­˜åŸå§‹å›¾åƒï¼ˆBGRæ ¼å¼ï¼‰
            original_filename = f"step_{self.step_counter:04d}_{timestamp}_original.jpg"
            original_path = os.path.join(self.images_dir, original_filename)
            cv2.imwrite(original_path, original_frame)
            
            # ä¿å­˜å¤„ç†åçš„å›¾åƒï¼ˆéœ€è¦è½¬æ¢å›BGRæ ¼å¼ï¼‰
            processed_bgr = cv2.cvtColor(processed_frame, cv2.COLOR_RGB2BGR)
            processed_filename = f"step_{self.step_counter:04d}_{timestamp}_processed.jpg"
            processed_path = os.path.join(self.images_dir, processed_filename)
            cv2.imwrite(processed_path, processed_bgr)
            
            print(f"ğŸ’¾ å·²ä¿å­˜å›¾åƒ: {original_filename} & {processed_filename}")
            
        except Exception as e:
            print(f"âš ï¸  å›¾åƒä¿å­˜å¤±è´¥: {e}")
        
    def normalize_joint_angle(self, joint_idx, angle):
        """å°†å…³èŠ‚è§’åº¦å½’ä¸€åŒ–åˆ°[-1, 1]èŒƒå›´"""
        min_angle, max_angle = self.JOINT_LIMITS[joint_idx]
        # å½’ä¸€åŒ–åˆ°[-1, 1]: (angle - center) / half_range
        center = (min_angle + max_angle) / 2.0
        half_range = (max_angle - min_angle) / 2.0
        normalized = (angle - center) / half_range
        return max(-1.0, min(1.0, normalized))
    
    def denormalize_joint_angle(self, joint_idx, normalized_value):
        """å°†å½’ä¸€åŒ–å€¼[-1, 1]è½¬æ¢å›å®é™…è§’åº¦"""
        min_angle, max_angle = self.JOINT_LIMITS[joint_idx]
        center = (min_angle + max_angle) / 2.0
        half_range = (max_angle - min_angle) / 2.0
        angle = normalized_value * half_range + center
        return max(min_angle, min(max_angle, angle))

    def get_observation(self, prompt="pick up the object"):
        """è·å–å½“å‰è§‚æµ‹ - å›¾åƒ+å…³èŠ‚çŠ¶æ€+æç¤º"""
        # è¯»å–æ‘„åƒå¤´
        cap = cv2.VideoCapture(0)
        ret, frame = cap.read()
        cap.release()
        
        if not ret:
            # æ²¡æ‘„åƒå¤´å°±ç”¨é»‘å›¾
            frame = np.zeros((480, 640, 3), dtype=np.uint8)
            original_frame = frame.copy()
        else:
            # ä¿å­˜åŸå§‹å›¾åƒï¼ˆBGRæ ¼å¼ï¼Œç”¨äºä¿å­˜ï¼‰
            original_frame = frame.copy()
            
            # å¤„ç†å›¾åƒç”¨äºå‘é€ç»™æœåŠ¡å™¨
            frame = cv2.resize(frame, (224, 224))
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        
        # ä¿å­˜å›¾åƒåˆ°æœ¬åœ°
        self._save_images(original_frame, frame)
        
        # è¯»å–å…³èŠ‚è§’åº¦
        for i in range(6):
            angle = self.arm.Arm_serial_servo_read(i + 1)
            if angle is not None:
                self.joint_angles[i] = float(angle)
        
        # ä½¿ç”¨æ”¹è¿›çš„å½’ä¸€åŒ–ç®—æ³•å¤„ç†å…³èŠ‚ä½ç½®
        joint_positions = []
        for i in range(5):  # å‰5ä¸ªå…³èŠ‚
            if i < len(self.joint_angles):
                normalized = self.normalize_joint_angle(i, self.joint_angles[i])
                joint_positions.append(normalized)
            else:
                joint_positions.append(0.0)
        
        # è¡¥é½åˆ°7ç»´ (DROIDæ ¼å¼) - æ·»åŠ ä¸¤ä¸ªè™šæ‹Ÿè…•éƒ¨å…³èŠ‚
        joint_positions.extend([0.0, 0.0])  # ç¬¬6ã€7å…³èŠ‚è®¾ä¸º0 (æ— å¯¹åº”ç¡¬ä»¶)
        
        # å¤¹çˆªä½ç½® (å•ç‹¬å¤„ç†)
        gripper_angle = self.joint_angles[5] if len(self.joint_angles) > 5 else 90.0
        gripper_pos = self.normalize_joint_angle(5, gripper_angle)
        
        # æ„å»ºè§‚æµ‹ - æŒ‰DROIDæ ¼å¼
        obs = {
            "observation/exterior_image_1_left": frame,  # numpyæ•°ç»„
            "observation/wrist_image_left": frame,  # ç”¨åŒä¸€ä¸ªå›¾åƒ
            "observation/joint_position": np.array(joint_positions, dtype=np.float32),  # 7ä¸ªå…³èŠ‚
            "observation/gripper_position": np.array([gripper_pos], dtype=np.float32),
            "prompt": prompt
        }
        
        # ğŸ” è¯¦ç»†è°ƒè¯•è¾“å‡º - æ‰“å°å‘é€ç»™æœåŠ¡å™¨çš„æ‰€æœ‰æ•°æ®
        print("\n" + "="*60)
        print("ğŸ“¤ å‘é€ç»™æœåŠ¡å™¨çš„è§‚æµ‹æ•°æ®:")
        print("="*60)
        
        # æ‰“å°å›¾åƒä¿¡æ¯
        print(f"ğŸ–¼ï¸  å›¾åƒä¿¡æ¯:")
        print(f"   - å›¾åƒå½¢çŠ¶: {frame.shape}")
        print(f"   - å›¾åƒæ•°æ®ç±»å‹: {frame.dtype}")
        
        # æ‰“å°åŸå§‹å…³èŠ‚è§’åº¦
        print(f"ğŸ”§ åŸå§‹å…³èŠ‚è§’åº¦ (åº¦):")
        for i, angle in enumerate(self.joint_angles):
            print(f"   - å…³èŠ‚{i+1}: {angle:.2f}Â°")
        
        # æ‰“å°å½’ä¸€åŒ–åçš„å…³èŠ‚ä½ç½®
        print(f"ğŸ“ å½’ä¸€åŒ–å…³èŠ‚ä½ç½® [-1,1]:")
        joint_pos_array = obs["observation/joint_position"]
        for i, pos in enumerate(joint_pos_array):
            if i < 5:
                original_angle = self.joint_angles[i]
                print(f"   - å…³èŠ‚{i+1}: {pos:.3f} (åŸå§‹: {original_angle:.2f}Â°)")
            else:
                print(f"   - å…³èŠ‚{i+1}: {pos:.3f} (å¡«å……å€¼)")
        
        # æ‰“å°å¤¹çˆªä¿¡æ¯
        gripper_array = obs["observation/gripper_position"]
        print(f"ğŸ¤ å¤¹çˆªä½ç½®:")
        print(f"   - åŸå§‹è§’åº¦: {self.joint_angles[5]:.2f}Â°")
        print(f"   - å½’ä¸€åŒ–ä½ç½®: {gripper_array[0]:.3f}")
        
        # æ‰“å°ä»»åŠ¡æç¤º
        print(f"ğŸ’¬ ä»»åŠ¡æç¤º: '{prompt}'")
        
        # æ‰“å°è§‚æµ‹å­—å…¸çš„é”®å’Œæ•°æ®ç±»å‹
        print(f"ğŸ“‹ è§‚æµ‹æ•°æ®ç»“æ„:")
        for key, value in obs.items():
            if isinstance(value, np.ndarray):
                print(f"   - {key}: {type(value).__name__} {value.shape} {value.dtype}")
            else:
                print(f"   - {key}: {type(value).__name__} = '{value}'")
        
        print("="*60)
        
        return obs
    
    def predict_async(self, prompt):
        """å¼‚æ­¥é¢„æµ‹ä¸‹ä¸€è½®åŠ¨ä½œ"""
        def prediction_worker():
            try:
                print("ğŸ”® [å¼‚æ­¥] å¼€å§‹ä¸‹ä¸€è½®é¢„æµ‹...")
                observation = self.get_observation(prompt)
                if observation is None:
                    print("âš ï¸ [å¼‚æ­¥] æ— æ³•è·å–è§‚æµ‹æ•°æ®")
                    return
                
                start_time = time.time()
                response = self.policy.infer(observation)
                inference_time = time.time() - start_time
                
                with self.prediction_lock:
                    self.next_prediction = {
                        'response': response,
                        'inference_time': inference_time,
                        'step': self.step_counter + 1
                    }
                
                print(f"ğŸ”® [å¼‚æ­¥] é¢„æµ‹å®Œæˆï¼Œè€—æ—¶ {inference_time:.3f}s")
                
            except Exception as e:
                print(f"âŒ [å¼‚æ­¥] é¢„æµ‹å¤±è´¥: {e}")
            finally:
                self.is_predicting = False
        
        if not self.is_predicting:
            self.is_predicting = True
            thread = threading.Thread(target=prediction_worker, daemon=True)
            thread.start()
    
    def get_next_prediction(self):
        """è·å–å¼‚æ­¥é¢„æµ‹çš„ç»“æœ"""
        with self.prediction_lock:
            result = self.next_prediction
            self.next_prediction = None
            return result
    
    def execute_action(self, action_data, prompt=None, enable_parallel=True):
        """æ‰§è¡ŒåŠ¨ä½œåºåˆ—ï¼Œæ”¯æŒå¹¶è¡Œé¢„æµ‹ä¸‹ä¸€è½®"""
        if action_data is None:
            print("âš ï¸ æ”¶åˆ°ç©ºçš„åŠ¨ä½œæ•°æ®")
            return
            
        if not isinstance(action_data, dict) or "actions" not in action_data:
            print(f"âš ï¸ åŠ¨ä½œæ•°æ®ä¸­æ²¡æœ‰ 'actions' å­—æ®µï¼Œå¯ç”¨å­—æ®µ: {list(action_data.keys())}")
            return
            
        actions = action_data["actions"]
        
        # å¤„ç†åŠ¨ä½œæ ¼å¼
        if len(actions) == 0:
            print("âš ï¸ æ”¶åˆ°ç©ºåŠ¨ä½œ")
            return
        
        total_steps = len(actions)
        prediction_trigger_step = 7  # å›ºå®šåœ¨ç¬¬7æ­¥å¯åŠ¨é¢„æµ‹
        
        print(f"ğŸ¯ å¼€å§‹æ‰§è¡ŒåŠ¨ä½œåºåˆ—ï¼Œå…± {total_steps} æ­¥")
        if enable_parallel and prompt:
            print(f"ğŸ“Š å¹¶è¡Œç­–ç•¥: ç¬¬{prediction_trigger_step}æ­¥æ—¶å¯åŠ¨ä¸‹ä¸€è½®é¢„æµ‹")
        else:
            print("ğŸ“Š ä¸²è¡Œæ‰§è¡Œæ¨¡å¼")
        
        # æ‰§è¡Œå®Œæ•´çš„åŠ¨ä½œåºåˆ—
        for step_idx, action in enumerate(actions):
            # DROIDåŠ¨ä½œæ ¼å¼: 8ç»´ (7ä¸ªå…³èŠ‚é€Ÿåº¦ + 1ä¸ªå¤¹çˆªä½ç½®)
            if len(action) < 8:
                print(f"âš ï¸ ç¬¬{step_idx+1}æ­¥åŠ¨ä½œç»´åº¦ä¸è¶³: {len(action)}, æœŸæœ›8ä¸ªï¼Œè·³è¿‡")
                continue
            
            # æå–å…³èŠ‚é€Ÿåº¦ (å‰7ä¸ª) å’Œå¤¹çˆªä½ç½® (ç¬¬8ä¸ª)
            joint_velocities = action[:7]  # 7ä¸ªå…³èŠ‚çš„é€Ÿåº¦
            gripper_position = action[7]   # å¤¹çˆªä½ç½®
            
            print(f"  ğŸ”§ æ‰§è¡Œç¬¬ {step_idx+1}/{len(actions)} æ­¥")
            print(f"    å…³èŠ‚é€Ÿåº¦: {joint_velocities}")
            print(f"    å¤¹çˆªä½ç½®: {gripper_position}")
            
            # å°†é€Ÿåº¦è½¬æ¢ä¸ºä½ç½®å¢é‡ (ç®€å•ç§¯åˆ†)
            # é€Ÿåº¦èŒƒå›´å‡è®¾ä¸º[-1, 1]ï¼Œè½¬æ¢ä¸ºè§’åº¦å¢é‡
            angles = []
            for i in range(5):  # åªå¤„ç†å‰5ä¸ªå…³èŠ‚ (å¯¹åº”Dofbotçš„å‰5ä¸ªå…³èŠ‚)
                if i < len(joint_velocities):
                    # å½“å‰è§’åº¦ + é€Ÿåº¦å¢é‡
                    velocity = joint_velocities[i]
                    # é™åˆ¶é€Ÿåº¦å¢é‡ (é˜²æ­¢è¿‡å¤§çš„è·³è·ƒ)
                    velocity = max(-0.3, min(0.3, velocity))  # é™åˆ¶æœ€å¤§é€Ÿåº¦
                    
                    # è®¡ç®—æ–°è§’åº¦ (å½“å‰è§’åº¦ + é€Ÿåº¦å¢é‡ * æ—¶é—´æ­¥é•¿)
                    current_angle = self.joint_angles[i]
                    angle_increment = velocity * 15.0  # 15åº¦æœ€å¤§å¢é‡
                    new_angle = current_angle + angle_increment
                    
                    # ä½¿ç”¨ç²¾ç¡®çš„å…³èŠ‚é™åˆ¶
                    new_angle = self.denormalize_joint_angle(i, 
                        self.normalize_joint_angle(i, new_angle))
                    angles.append(int(new_angle))
                else:
                    angles.append(int(self.joint_angles[i]))
            
            # å¤„ç†å¤¹çˆª (ä½¿ç”¨ä½ç½®æ§åˆ¶ï¼Œä¸æ˜¯é€Ÿåº¦)
            gripper_angle = self.denormalize_joint_angle(5, gripper_position)
            angles.append(int(gripper_angle))
            
            # å®‰å…¨æ£€æŸ¥ - ç¡®ä¿æ‰€æœ‰è§’åº¦åœ¨æœ‰æ•ˆèŒƒå›´å†…
            safe_angles = []
            for i, angle in enumerate(angles):
                min_angle, max_angle = self.JOINT_LIMITS[i]
                safe_angle = max(min_angle, min(max_angle, angle))
                safe_angles.append(safe_angle)
            
            print(f"    ç›®æ ‡è§’åº¦: {safe_angles}")
            
            # æ‰§è¡ŒåŠ¨ä½œ
            self.arm.Arm_serial_servo_write6(
                safe_angles[0], safe_angles[1], safe_angles[2], 
                safe_angles[3], safe_angles[4], safe_angles[5], 
                600  # 600msæ‰§è¡Œæ—¶é—´ï¼Œå¹³æ»‘ä½†ä¸å¤ªæ…¢
            )
            
            # æ›´æ–°çŠ¶æ€
            with self.joint_angles_lock:
                self.joint_angles = [float(a) for a in safe_angles]
            
            # ğŸ”® å…³é”®ä¼˜åŒ–: åœ¨ç¬¬7æ­¥æ—¶å¯åŠ¨ä¸‹ä¸€è½®é¢„æµ‹
            if (enable_parallel and prompt and 
                step_idx == prediction_trigger_step - 1 and  # ç¬¬7æ­¥ï¼ˆç´¢å¼•6ï¼‰
                not self.is_predicting):                     # è¿˜æ²¡å¼€å§‹é¢„æµ‹
                print(f"ğŸš€ [å¹¶è¡Œ] åœ¨ç¬¬{step_idx + 1}æ­¥å¯åŠ¨ä¸‹ä¸€è½®é¢„æµ‹")
                self.predict_async(prompt)
            
            # åœ¨ç¬¬7æ­¥æ—¶å¯åŠ¨å¼‚æ­¥é¢„æµ‹
            if (enable_parallel and prompt and 
                step_idx + 1 == prediction_trigger_step and 
                hasattr(self, 'start_async_prediction')):
                print(f"ğŸ”® ç¬¬{prediction_trigger_step}æ­¥: å¯åŠ¨å¼‚æ­¥é¢„æµ‹ä¸‹ä¸€è½®...")
                self.start_async_prediction(prompt)
            
            # ç­‰å¾…åŠ¨ä½œå®Œæˆ
            time.sleep(0.6)  # ä¸æ‰§è¡Œæ—¶é—´åŒ¹é…
        
        print(f"âœ… åŠ¨ä½œåºåˆ—æ‰§è¡Œå®Œæˆ")
    
    def print_joint_status(self):
        """æ‰“å°å½“å‰å…³èŠ‚çŠ¶æ€"""
        print("ğŸ”§ å½“å‰å…³èŠ‚çŠ¶æ€:")
        for i, (name, angle) in enumerate(zip(self.JOINT_NAMES, self.joint_angles)):
            min_angle, max_angle = self.JOINT_LIMITS[i]
            normalized = self.normalize_joint_angle(i, angle)
            print(f"  {name:15}: {angle:6.1f}Â° (èŒƒå›´: {min_angle:3.0f}-{max_angle:3.0f}Â°, å½’ä¸€åŒ–: {normalized:+.3f})")

    def run(self, prompt="pick up the red block"):
        """ä¸»å¾ªç¯ - ä½¿ç”¨openpi_clientæ‰§è¡Œæ§åˆ¶"""
        print(f"ğŸš€ å¼€å§‹æ‰§è¡Œä»»åŠ¡: '{prompt}'")
        print(f"ğŸ¤– Dofboté…ç½®: {len(self.JOINT_NAMES)}ä¸ªå…³èŠ‚")
        self.print_joint_status()
        
        try:
            while True:
                self.step_counter += 1
                print(f"\nğŸš€ === æ­¥éª¤ {self.step_counter} å¼€å§‹ ===")
                
                # ğŸ”® æ£€æŸ¥æ˜¯å¦æœ‰å¼‚æ­¥é¢„æµ‹ç»“æœå¯ç”¨
                cached_prediction = self.get_next_prediction()
                
                if cached_prediction:
                    print(f"âš¡ ä½¿ç”¨å¼‚æ­¥é¢„æµ‹ç»“æœ (æ­¥éª¤ {cached_prediction['step']})")
                    action_data = cached_prediction['response']
                    inference_time = cached_prediction['inference_time']
                    
                    # æ˜¾ç¤ºè§‚æµ‹æ•°æ®æ‘˜è¦ï¼ˆä»éœ€è¦è·å–å½“å‰è§‚æµ‹ç”¨äºæ˜¾ç¤ºï¼‰
                    obs = self.get_observation(prompt)
                    joint_pos = obs["observation/joint_position"]
                    gripper_pos = obs["observation/gripper_position"]
                    image_shape = obs["observation/exterior_image_1_left"].shape
                    print(f"  ğŸ“Š è§‚æµ‹æ‘˜è¦: å›¾åƒ{image_shape}, å…³èŠ‚ä½ç½®{joint_pos.shape}, å¤¹çˆªä½ç½®{gripper_pos.shape}")
                else:
                    # æ²¡æœ‰ç¼“å­˜ç»“æœï¼Œè¿›è¡ŒåŒæ­¥é¢„æµ‹
                    print("ğŸ”„ è¿›è¡ŒåŒæ­¥é¢„æµ‹...")
                    obs = self.get_observation(prompt)
                    
                    # æ˜¾ç¤ºè§‚æµ‹æ•°æ®æ‘˜è¦
                    joint_pos = obs["observation/joint_position"]
                    gripper_pos = obs["observation/gripper_position"]
                    image_shape = obs["observation/exterior_image_1_left"].shape
                    print(f"  ğŸ“Š è§‚æµ‹æ‘˜è¦: å›¾åƒ{image_shape}, å…³èŠ‚ä½ç½®{joint_pos.shape}, å¤¹çˆªä½ç½®{gripper_pos.shape}")
                    
                    # ä½¿ç”¨openpi_clientå‘é€åˆ°æœåŠ¡å™¨å¹¶æ¥æ”¶åŠ¨ä½œ
                    print("ğŸ“¡ æ­£åœ¨å‘é€è§‚æµ‹æ•°æ®åˆ°æœåŠ¡å™¨...")
                    start_time = time.time()
                    action_data = self.policy.infer(obs)
                    inference_time = time.time() - start_time
                
                print("ğŸ“¥ æ”¶åˆ°æœåŠ¡å™¨å“åº”:")
                print(f"   - å“åº”ç±»å‹: {type(action_data)}")
                print(f"   - ç½‘ç»œå¾€è¿”æ—¶é—´: {inference_time:.3f}s")
                
                # æ˜¾ç¤ºæœåŠ¡å™¨å“åº”çš„ç»Ÿè®¡ä¿¡æ¯
                actions = action_data.get('actions', [])
                print(f"ğŸ“Š æ­¥éª¤ {self.step_counter} æ€»ç»“:")
                print(f"   - åŠ¨ä½œåºåˆ—é•¿åº¦: {len(actions)}")
                if len(actions) > 0:
                    print(f"   - é¦–ä¸ªåŠ¨ä½œç»´åº¦: {len(actions[0])}")
                    print(f"   - é¦–ä¸ªåŠ¨ä½œèŒƒå›´: [{min(actions[0]):.3f}, {max(actions[0]):.3f}]")
                print(f"   - ç­–ç•¥æ¨ç†æ—¶é—´: {action_data.get('policy_timing', {}).get('infer_ms', 'N/A')} ms")
                print(f"   - æœåŠ¡å™¨æ¨ç†æ—¶é—´: {action_data.get('server_timing', {}).get('infer_ms', 'N/A')} ms")
                
                # æ‰§è¡ŒåŠ¨ä½œåºåˆ—
                self.execute_action(action_data)
                
                # æ˜¾ç¤ºæ‰§è¡Œåçš„å…³èŠ‚çŠ¶æ€
                self.print_joint_status()
                
                # ä¸éœ€è¦é¢å¤–çš„sleepï¼Œå› ä¸ºexecute_actionå·²ç»åŒ…å«äº†ç­‰å¾…æ—¶é—´
                    
        except KeyboardInterrupt:
            print("\nğŸ›‘ ç”¨æˆ·ä¸­æ–­")
        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}")
        finally:
            # å›åˆ°å®‰å…¨ä½ç½®
            print("ğŸ”§ è¿”å›å®‰å…¨ä½ç½®...")
            self.arm.Arm_serial_servo_write6(*self.SAFE_POSITION, 1000)
            time.sleep(1.0)
            del self.arm
            print("ğŸ§¹ æ¸…ç†å®Œæˆ")


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Yahboomæœºæ¢°è‡‚ + pi0.5è¿œç¨‹æ§åˆ¶")
    parser.add_argument("--host", default="12.148.158.61", help="æœåŠ¡å™¨IP")
    parser.add_argument("--port", type=int, default=8000, help="æœåŠ¡å™¨ç«¯å£")
    parser.add_argument("--task", default="pick up the object", help="ä»»åŠ¡æè¿°")
    parser.add_argument("--camera", type=int, default=0, help="æ‘„åƒå¤´ID")
    
    args = parser.parse_args()
    
    print("ğŸ¤– Yahboomæœºæ¢°è‡‚ + pi0.5è¿œç¨‹æ§åˆ¶ç³»ç»Ÿ")
    print(f"æœåŠ¡å™¨: {args.host}:{args.port}")
    print(f"ä»»åŠ¡: {args.task}")
    
    client = YahboomPi05Client(args.host, args.port)
    client.run(args.task)


if __name__ == "__main__":
    main()